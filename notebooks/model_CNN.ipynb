{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Useful libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import copy\n",
        "import pickle\n",
        "from urllib.request import urlretrieve\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import random_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from matplotlib.colors import TwoSlopeNorm\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Additional input\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "# !pip install torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "# !pip install perlin-noise\n",
        "from perlin_noise import PerlinNoise\n",
        "import random\n",
        "\n",
        "from cycler import cycler\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "# Set the color scheme\n",
        "sns.set_theme()\n",
        "colors = ['#0076C2', '#EC6842', '#A50034', '#009B77', '#FFB81C', '#E03C31', '#6CC24A', '#EF60A3', '#0C2340', '#00B8C8', '#6F1D77']\n",
        "plt.rcParams['axes.prop_cycle'] = cycler(color=colors)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SsZbVLFE9xe",
        "outputId": "bb59c43f-e3bf-47ec-f1ea-9b00a735a53f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n",
            "Collecting perlin-noise\n",
            "  Downloading perlin_noise-1.12-py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: perlin-noise\n",
            "Successfully installed perlin-noise-1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def center_grid_graph(dim1, dim2):\n",
        "    '''\n",
        "    Create graph from a rectangular grid of dimensions dim1 x dim2\n",
        "    Returns networkx graph connecting the grid centers and corresponding\n",
        "    node positions\n",
        "    ------\n",
        "    dim1: int\n",
        "        number of grids in the x direction\n",
        "    dim2: int\n",
        "        number of grids in the y direction\n",
        "    '''\n",
        "    G = nx.grid_2d_graph(dim1, dim2, create_using=nx.DiGraph)\n",
        "    # for the position, it is assumed that they are located in the centre of each grid\n",
        "    pos = {i:(x+0.5,y+0.5) for i, (x,y) in enumerate(G.nodes())}\n",
        "\n",
        "    #change keys from (x,y) format to i format\n",
        "    mapping = dict(zip(G, range(0, G.number_of_nodes())))\n",
        "    G = nx.relabel_nodes(G, mapping)\n",
        "\n",
        "    return G, pos\n",
        "\n",
        "def create_grid_dataset(dataset_folder, n_sim, start_sim=1, number_grids=64):\n",
        "    '''\n",
        "    Creates a pytorch geometric dataset with n_sim simulations\n",
        "    returns a regular grid graph dataset\n",
        "    ------\n",
        "    dataset_folder: str, path-like\n",
        "        path to raw dataset location\n",
        "    n_sim: int\n",
        "        number of simulations used in the dataset creation\n",
        "    '''\n",
        "    assert os.path.exists(dataset_folder), \"There is no raw dataset folder\"\n",
        "    grid_dataset = []\n",
        "\n",
        "    graph, pos = center_grid_graph(number_grids,number_grids)\n",
        "\n",
        "    for i in tqdm(range(start_sim,start_sim+n_sim)):\n",
        "\n",
        "        DEM = np.loadtxt(f\"{dataset_folder}/DEM/DEM_{i}.txt\")[:,2]\n",
        "        WD = np.loadtxt(f\"{dataset_folder}/WD/WD_{i}.txt\")\n",
        "#         VX = np.loadtxt(f\"{dataset_folder}\\\\VX\\\\VX_{i}.txt\")\n",
        "#         VY = np.loadtxt(f\"{dataset_folder}\\\\VY\\\\VY_{i}.txt\")\n",
        "\n",
        "        grid_i = convert_to_pyg(graph, pos, DEM, WD)  # VX, VY\n",
        "        grid_dataset.append(grid_i)\n",
        "\n",
        "    return grid_dataset\n",
        "\n",
        "\n",
        "def convert_to_pyg(graph, pos, DEM, WD):  # VX, VY\n",
        "    '''Converts a graph or mesh into a PyTorch Geometric Data type\n",
        "    Then, add position, DEM, and water variables to data object'''\n",
        "    DEM = DEM.reshape(-1)\n",
        "\n",
        "    edge_index = torch.LongTensor(list(graph.edges)).t().contiguous()\n",
        "    row, col = edge_index\n",
        "\n",
        "    data = Data()\n",
        "\n",
        "    delta_DEM = torch.FloatTensor(DEM[col]-DEM[row])\n",
        "    coords = torch.FloatTensor(get_coords(pos))\n",
        "    edge_relative_distance = coords[col] - coords[row]\n",
        "    edge_distance = torch.norm(edge_relative_distance, dim=1)\n",
        "    edge_slope = delta_DEM/edge_distance\n",
        "\n",
        "    data.edge_index = edge_index\n",
        "    data.edge_distance = edge_distance\n",
        "    data.edge_slope = edge_slope\n",
        "    data.edge_relative_distance = edge_relative_distance\n",
        "\n",
        "    data.num_nodes = graph.number_of_nodes()\n",
        "    data.pos = torch.tensor(list(pos.values()))\n",
        "    data.DEM = torch.FloatTensor(DEM)\n",
        "    data.WD = torch.FloatTensor(WD.T)\n",
        "#     data.VX = torch.FloatTensor(VX.T)\n",
        "#     data.VY = torch.FloatTensor(VY.T)\n",
        "\n",
        "    return data\n",
        "\n",
        "def get_coords(pos):\n",
        "    '''\n",
        "    Returns array of dimensions (n_nodes, 2) containing x and y coordinates of each node\n",
        "    ------\n",
        "    pos: dict\n",
        "        keys: (x,y) index of every node\n",
        "        values: spatial x and y positions of each node\n",
        "    '''\n",
        "    return np.array([xy for xy in pos.values()])\n",
        "\n",
        "\n",
        "def save_database(dataset, name, out_path='datasets'):\n",
        "    '''\n",
        "    This function saves the geometric database into a pickle file\n",
        "    The name of the file is given by the type of graph and number of simulations\n",
        "    ------\n",
        "    dataset: list\n",
        "        list of geometric datasets for grid and mesh\n",
        "    names: str\n",
        "        name of saved dataset\n",
        "    out_path: str, path-like\n",
        "        output file location\n",
        "    '''\n",
        "    n_sim = len(dataset)\n",
        "    path = f\"{out_path}/{name}.pkl\"\n",
        "\n",
        "    if os.path.exists(path):\n",
        "        os.remove(path)\n",
        "    elif not os.path.exists(out_path):\n",
        "        os.mkdir(out_path)\n",
        "\n",
        "    pickle.dump(dataset, open(path, \"wb\" ))\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "Jcf-x79wFgCr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization to access your Google Drive from Colab.\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# After mounting, you can navigate to a specific folder using the usual UNIX cd command.\n",
        "# Replace 'your_folder_path' with the actual path of your folder inside Google Drive.\n",
        "folder_path = '/content/drive/MyDrive/DSAIE/FLOOD/raw_datasets/'  # Example path\n",
        "\n",
        "%cd \"$folder_path\""
      ],
      "metadata": {
        "id": "rIn361zTHEsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a615206d-a250-432b-fcbe-1d8ebdd841d6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/DSAIE/FLOOD/raw_datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = folder_path\n",
        "train_dataset = 'DEM/'\n",
        "\n",
        "dataset_folder = data_folder\n",
        "n_sim = 80\n",
        "start_sim = 1\n",
        "dataset_name = 'grid'\n",
        "\n",
        "datasets_folder = 'datasets'\n",
        "if not os.path.exists(datasets_folder):\n",
        "    os.makedirs(datasets_folder)\n",
        "\n",
        "dataset_dir = datasets_folder + '/train'\n",
        "\n",
        "##################### Use this code to create local pickle file #####################\n",
        "pyg_dataset = create_grid_dataset(dataset_folder, n_sim=n_sim)\n",
        "save_database(pyg_dataset, name=dataset_name, out_path=dataset_dir)\n",
        "\n",
        "def load_dataset(dataset_name, dataset_folder='datasets/'):\n",
        "    '''\n",
        "    Loads dataset, composed by a list of pytorch geometric data objects\n",
        "    only accepts files of .pkl format\n",
        "    ------\n",
        "    dataset_name: str\n",
        "        name of the dataset to be loaded\n",
        "    '''\n",
        "\n",
        "    path = f\"{dataset_folder}/{dataset_name}.pkl\"\n",
        "\n",
        "    with open(path, 'rb') as file:\n",
        "        dataset = pickle.load(file)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_dataset = load_dataset(dataset_name=dataset_name, dataset_folder=dataset_dir)"
      ],
      "metadata": {
        "id": "zYeK3WSMFkAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200268f4-8988-4612-c77b-a512b7002d51"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [02:28<00:00,  1.86s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = folder_path\n",
        "test_dataset = 'DEM/'\n",
        "\n",
        "dataset_folder = data_folder\n",
        "n_sim = 20\n",
        "start_sim = 501\n",
        "dataset_name = 'grid_test'\n",
        "\n",
        "datasets_folder = 'datasets'\n",
        "if not os.path.exists(datasets_folder):\n",
        "    os.makedirs(datasets_folder)\n",
        "\n",
        "dataset_dir = datasets_folder + '/test'\n",
        "\n",
        "##################### Use this code to create local pickle file #####################\n",
        "pyg_dataset = create_grid_dataset(dataset_folder, n_sim=n_sim)\n",
        "save_database(pyg_dataset, name=dataset_name, out_path=dataset_dir)\n",
        "\n",
        "test_dataset = load_dataset(dataset_name=dataset_name, dataset_folder=dataset_dir)"
      ],
      "metadata": {
        "id": "il8VXoYzQzw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6563d16-a312-45d5-c9d1-df899b835c8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  9.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_dataset(dataset, scaler_DEM, scaler_WD):\n",
        "    min_DEM, max_DEM = scaler_DEM.data_min_[0], scaler_DEM.data_max_[0]\n",
        "#     min_VX, max_VX = scaler_VX.data_min_[0], scaler_VX.data_max_[0]\n",
        "#     min_VY, max_VY = scaler_VY.data_min_[0], scaler_VY.data_max_[0]\n",
        "    min_WD, max_WD = scaler_WD.data_min_[0], scaler_WD.data_max_[0]\n",
        "    normalized_dataset = []\n",
        "    for idx in range(len(dataset)):\n",
        "        DEM = dataset[idx]['DEM']\n",
        "#         VX = dataset[idx]['VX']\n",
        "#         VY = dataset[idx]['VY']\n",
        "        WD = dataset[idx]['WD']\n",
        "        norm_DEM = (DEM - min_DEM) / (max_DEM - min_DEM)\n",
        "#         norm_VX = (VX - min_VX) / (max_VX - min_VX)\n",
        "#         norm_VY = (VY - min_VY) / (max_VY - min_VY)\n",
        "        norm_WD = (WD - min_WD) / (max_WD - min_WD)\n",
        "        normalized_dataset.append((norm_DEM, norm_WD))\n",
        "    return normalized_dataset\n",
        "\n",
        "\n",
        "# Normalize the inputs and outputs using training dataset\n",
        "scaler_DEM = MinMaxScaler() # Can store DEM, VX, VY as one 'input' Scaler\n",
        "# scaler_VX = MinMaxScaler()\n",
        "# scaler_VY = MinMaxScaler()\n",
        "scaler_WD = MinMaxScaler()\n",
        "\n",
        "for idx in range(len(train_dataset)):\n",
        "    scaler_DEM.partial_fit(train_dataset[idx]['DEM'].reshape(1, -1).T.cpu())\n",
        "#     scaler_VX.partial_fit(train_dataset[idx]['VX'].reshape(train_dataset[0]['VX'].shape[0], -1).T.cpu())\n",
        "#     scaler_VY.partial_fit(train_dataset[idx]['VY'].reshape(train_dataset[0]['VY'].shape[0], -1).T.cpu())\n",
        "    scaler_WD.partial_fit(train_dataset[idx]['WD'].reshape(1, -1).T.cpu())\n",
        "\n",
        "normalized_train_dataset = normalize_dataset(train_dataset, scaler_DEM, scaler_WD)\n",
        "normalized_test_dataset = normalize_dataset(train_dataset, scaler_DEM, scaler_WD)\n",
        "\n",
        "# Split dataset into train, validation, and testing\n",
        "train_percnt = 0.8\n",
        "train_size = int(train_percnt * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "training_dataset, val_dataset = random_split(normalized_train_dataset, [train_size, val_size])\n",
        "\n",
        "# Dataset has two variables, training data DEM, target WD\n",
        "print('Amount of variables', len(normalized_train_dataset[0]))\n",
        "print('Size of DEM data', len(normalized_train_dataset[0][0]))\n",
        "print(f'Size of WD data ({len(normalized_train_dataset[0][1])}, {len(normalized_train_dataset[0][1][0])})')\n",
        "print(normalized_train_dataset[0][0])"
      ],
      "metadata": {
        "id": "U8NWW9o1O8kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "891eb05b-30bd-4584-bf99-3be6992c4267"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of variables 2\n",
            "Size of DEM data 4096\n",
            "Size of WD data (4096, 97)\n",
            "tensor([0.4818, 0.4313, 0.3685,  ..., 0.5115, 0.5253, 0.5234])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape_pyg(dataset):\n",
        "  reshaped_dataset = []\n",
        "\n",
        "  for input_tensor, output_tensor in dataset:\n",
        "      reshaped_input = input_tensor.view(-1, 64, 64)  # Reshaping the input tensor to 64x64\n",
        "      reshaped_output = output_tensor.view(-1, 64, 64, 97)  # Reshaping the output tensor to 64x64 for each of the 97 time steps\n",
        "      reshaped_dataset.append((reshaped_input, reshaped_output))\n",
        "\n",
        "  return reshaped_dataset"
      ],
      "metadata": {
        "id": "WJD2v3-puO-6"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape the dataset\n",
        "reshaped_train_dataset = reshape_pyg(normalized_train_dataset)\n",
        "\n",
        "# Split dataset into train, validation, and testing for reshaped train_dataset\n",
        "train_percnt = 0.8\n",
        "train_size = int(train_percnt * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "training_dataset, val_dataset = random_split(reshaped_train_dataset, [train_size, val_size])"
      ],
      "metadata": {
        "id": "LUmhH28WwOFG"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reshaped_train_dataset[0][0].shape"
      ],
      "metadata": {
        "id": "IzjArTOh1Ioh",
        "outputId": "9a9a5d01-fcfb-4fee-d5e6-67d341627556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize, reshape test dataset\n",
        "normalized_test_dataset = normalize_dataset(test_dataset, scaler_DEM, scaler_WD)\n",
        "reshaped_test_dataset = reshape_pyg(normalized_test_dataset)"
      ],
      "metadata": {
        "id": "AdLjtNQ0xKnH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "pgz3cmF4UeQp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias)]\n",
        "        if batch_norm:\n",
        "            layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
        "        layers.append(nn.PReLU())\n",
        "        layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias))\n",
        "\n",
        "        self.cnnblock = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.cnnblock(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, channels=[32, 64, 128], kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_blocks = nn.ModuleList([\n",
        "            CNNBlock(channels[block], channels[block+1], kernel_size, padding, bias,\n",
        "                     batch_norm=batch_norm)\n",
        "            for block in range(len(channels)-1)]\n",
        "            )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        outs = []\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            outs.append(x)\n",
        "            x = self.pool(x)\n",
        "        return outs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, channels=[128, 64, 32], kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.upconvs = nn.ModuleList([\n",
        "            nn.ConvTranspose2d(channels[block], channels[block+1], kernel_size=2, padding=0, stride=2)\n",
        "            for block in range(len(channels)-1)]\n",
        "            )\n",
        "        self.dec_blocks = nn.ModuleList([\n",
        "            CNNBlock(channels[block], channels[block+1], kernel_size, padding, bias,\n",
        "                     batch_norm=batch_norm)\n",
        "             for block in range(len(channels)-1)]\n",
        "             )\n",
        "\n",
        "    def forward(self, x, x_skips):\n",
        "        for i in range(len(x_skips)):\n",
        "            x = self.upconvs[i](x)\n",
        "            x = torch.cat((x, x_skips[-(1+i)]), dim=1)\n",
        "            x = self.dec_blocks[i](x)\n",
        "\n",
        "        x = self.dec_blocks[-1](x)\n",
        "        return x\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, node_features, out_dim=1, n_downsamples=3, initial_hid_dim=64, batch_norm=True,\n",
        "                 bias=True):\n",
        "        super(CNN, self).__init__()\n",
        "        hidden_channels = [initial_hid_dim*2**i for i in range(n_downsamples)]\n",
        "        encoder_channels = [node_features]+hidden_channels\n",
        "        decoder_channels = list(reversed(hidden_channels))+[out_dim]\n",
        "\n",
        "        self.encoder = Encoder(encoder_channels, kernel_size=3, padding=1,\n",
        "                               bias=bias, batch_norm=batch_norm)\n",
        "        self.decoder = Decoder(decoder_channels, kernel_size=3, padding=1,\n",
        "                               bias=bias, batch_norm=batch_norm)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x[-1], x[:-1])\n",
        "        x = nn.Sigmoid()(x)\n",
        "        return x\n",
        "\n",
        "# node_features = train_dataset[0]['DEM'].shape[0]\n",
        "node_features = training_dataset[0][0].shape[0]\n",
        "model = CNN(node_features=node_features, n_downsamples=4, initial_hid_dim=32,\n",
        "            batch_norm=True, bias=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset[0][0].shape"
      ],
      "metadata": {
        "id": "FKXvJvzy2o5y",
        "outputId": "6812ca0e-a158-4630-ed25-87163674dc8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, optimizer, device='cpu'):\n",
        "    model.to(device)\n",
        "    model.train() # specifies that the model is in training mode\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for batch in loader:\n",
        "        x = batch[0]\n",
        "        y = batch[1]\n",
        "\n",
        "        # Model prediction\n",
        "        preds = model(x)\n",
        "\n",
        "        # MSE loss function\n",
        "        loss = nn.MSELoss()(preds, y)\n",
        "\n",
        "        losses.append(loss.cpu().detach())\n",
        "\n",
        "        # Backpropagate and update weights\n",
        "        loss.backward()   # compute the gradients using backpropagation\n",
        "        optimizer.step()  # update the weights with the optimizer\n",
        "        optimizer.zero_grad(set_to_none=True)   # reset the computed gradients\n",
        "\n",
        "    losses = np.array(losses).mean()\n",
        "\n",
        "    return losses\n",
        "\n",
        "def evaluation(model, loader, device='cpu'):\n",
        "    model.to(device)\n",
        "    model.eval() # specifies that the model is in evaluation mode\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            x = batch[0]\n",
        "            y = batch[1]\n",
        "\n",
        "            # Model prediction\n",
        "            preds = model(x)\n",
        "\n",
        "            # MSE loss function\n",
        "            loss = nn.MSELoss()(preds, y)\n",
        "            losses.append(loss.cpu().detach())\n",
        "\n",
        "    losses = np.array(losses).mean()\n",
        "\n",
        "    return losses"
      ],
      "metadata": {
        "id": "HOBTTiMfIU-N"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 8\n",
        "num_epochs = 10\n",
        "\n",
        "# Create the optimizer to train the neural network via back-propagation\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Create the training and validation dataloaders to \"feed\" data to the model in batches\n",
        "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "# test_loader = DataLoader(normalized_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(reshaped_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "XrNWYzHjIgAW"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create vectors for the training and validation loss\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # Model training\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device=device)\n",
        "\n",
        "    # Model validation\n",
        "    val_loss = evaluation(model, val_loader, device=device)\n",
        "\n",
        "    if epoch == 1:\n",
        "        best_loss = val_loss\n",
        "\n",
        "    if val_loss<=best_loss:\n",
        "        best_model = copy.deepcopy(model)\n",
        "        best_loss = val_loss\n",
        "        best_epoch = epoch\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    if epoch%10 == 0:\n",
        "        print(\"epoch:\",epoch, \"\\t training loss:\", np.round(train_loss,4),\n",
        "                            \"\\t validation loss:\", np.round(val_loss,4))\n",
        "\n",
        "model = copy.deepcopy(best_model)"
      ],
      "metadata": {
        "id": "8Old7SUmL0Np",
        "outputId": "4f75a487-b220-41d4-aa91-c68f5644e618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-f8ef51774e5b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Model training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Model validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e781c4220a28>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Model prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# MSE loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-07b05447b924>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-07b05447b924>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-07b05447b924>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnnblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to - do list:\n",
        "# try this error \"Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor\""
      ],
      "metadata": {
        "id": "_2GlCoKn1636"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rN-ARGtbRy1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}