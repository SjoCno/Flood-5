{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6358f928",
   "metadata": {},
   "source": [
    "# Path of _multi-output_ model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20aba32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"CNN_multi_output models/\"\n",
    "saved_model = \"model_DIS_AUG_ts=48_02_02_24_112631_lr_0.001_epochs_200_bs_8\" + \".pth\"\n",
    "\n",
    "pre_trained_model = folder + saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8088621",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90661f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Useful libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Additional input\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "# !pip install torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "# !pip install perlin-noise\n",
    "from perlin_noise import PerlinNoise\n",
    "import random\n",
    "from loader import load_dataset\n",
    "from datetime import datetime\n",
    "\n",
    "from cycler import cycler\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Set the color scheme\n",
    "sns.set_theme()\n",
    "colors = ['#0076C2', '#EC6842', '#A50034', '#009B77', '#FFB81C', '#E03C31', '#6CC24A', '#EF60A3', '#0C2340', '#00B8C8', '#6F1D77']\n",
    "plt.rcParams['axes.prop_cycle'] = cycler(color=colors)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15094805",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e03bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'raw_datasets/'\n",
    "train_dataset = 'DEM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7ab6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File exists\n",
      "Test File 1 exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:14<00:00,  1.39it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = data_folder\n",
    "n_sim = 20\n",
    "start_sim = 500\n",
    "dataset_trainname = 'grid_vxvy'\n",
    "dataset_testname1 = 'test1'\n",
    "dataset_testname2 = 'test2'\n",
    "\n",
    "datasets_folder = 'datasets'\n",
    "if not os.path.exists(datasets_folder):\n",
    "    os.makedirs(datasets_folder)\n",
    "    \n",
    "dataset_traindir = datasets_folder + '/train'\n",
    "dataset_testdir = datasets_folder + '/test'\n",
    "\n",
    "\n",
    "if os.path.exists(dataset_traindir + '/' + dataset_trainname + '.pkl'):\n",
    "    print('Training File exists')\n",
    "\n",
    "    \n",
    "if os.path.exists(dataset_testdir + '/' + dataset_testname1 + '.pkl'):\n",
    "    print('Test File 1 exists')\n",
    "else:\n",
    "    ##################### Use this code to create local pickle file #####################\n",
    "    pyg_dataset = create_grid_dataset(dataset_folder, n_sim=n_sim, start_sim=start_sim)\n",
    "    save_database(pyg_dataset, name=dataset_testname1, out_path=dataset_testdir)\n",
    "    \n",
    "if os.path.exists(dataset_testdir + '/' + dataset_testname2 + '.pkl'):\n",
    "    print('Test File 2 exists')\n",
    "else:\n",
    "    ##################### Use this code to create local pickle file #####################\n",
    "    pyg_dataset = create_grid_dataset(dataset_folder, n_sim=n_sim, start_sim=10000)\n",
    "    save_database(pyg_dataset, name=dataset_testname2, out_path=dataset_testdir)    \n",
    "\n",
    "    \n",
    "train_dataset = load_dataset(dataset_name=dataset_trainname, dataset_folder=dataset_traindir)\n",
    "test_dataset1 = load_dataset(dataset_name=dataset_testname1, dataset_folder=dataset_testdir)\n",
    "test_dataset2 = load_dataset(dataset_name=dataset_testname2, dataset_folder=dataset_testdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da29e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset, scaler_DEM, scaler_WD):\n",
    "    \n",
    "    min_DEM, max_DEM = scaler_DEM.data_min_[0], scaler_DEM.data_max_[0]\n",
    "    min_WD, max_WD = scaler_WD.data_min_[0], scaler_WD.data_max_[0]\n",
    "    normalized_dataset = []\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        DEM = dataset[idx]['DEM']\n",
    "        WD = dataset[idx]['WD']\n",
    "        norm_DEM = (DEM - min_DEM) / (max_DEM - min_DEM)\n",
    "        norm_WD = (WD - min_WD) / (max_WD - min_WD)\n",
    "\n",
    "        DEM = norm_DEM.reshape(64,64)\n",
    "        WD = norm_WD[:,0].reshape(64,64)\n",
    "        \n",
    "        temp_dict = {}\n",
    "        temp_dict['Input'] = torch.stack((DEM, WD), dim=0)\n",
    "\n",
    "        WD_transposed = norm_WD[:, 1:].reshape(64,64, -1)\n",
    "        WD_transposed = WD_transposed.transpose(0, 2)\n",
    "        WD_transposed = WD_transposed.transpose(1, 2)\n",
    "        temp_dict['WD'] = WD_transposed\n",
    "    \n",
    "        normalized_dataset.append(temp_dict)\n",
    "    \n",
    "    return normalized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae88044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs and outputs using training dataset\n",
    "scaler_DEM = MinMaxScaler() # Can store DEM, VX, VY as one 'input' Scaler\n",
    "scaler_WD = MinMaxScaler()\n",
    "\n",
    "for index in range(len(train_dataset)): # =80\n",
    "    scaler_DEM.partial_fit(train_dataset[index]['DEM'].reshape(-1, 1).cpu())\n",
    "    scaler_WD.partial_fit(train_dataset[index]['WD'].reshape(-1, 1).cpu())\n",
    "\n",
    "normalized_train_dataset = normalize_dataset(train_dataset, scaler_DEM, scaler_WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33416845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into train, validation, and testing\n",
    "train_percnt = 0.8\n",
    "train_size = int(train_percnt * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "training_dataset, val_dataset = random_split(normalized_train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de280c1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07e04941",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for CNN:\n\tsize mismatch for decoder.upconvs.3.weight: copying a param with shape torch.Size([32, 1, 2, 2]) from checkpoint, the shape in current model is torch.Size([32, 96, 2, 2]).\n\tsize mismatch for decoder.upconvs.3.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.0.weight: copying a param with shape torch.Size([1, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 32, 3, 3]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.0.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.weight: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.running_mean: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.running_var: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.3.weight: copying a param with shape torch.Size([1, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 96, 3, 3]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.3.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 80\u001b[0m\n\u001b[0;32m     77\u001b[0m node_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     78\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN(node_features\u001b[38;5;241m=\u001b[39mnode_features, n_downsamples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, initial_hid_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \n\u001b[0;32m     79\u001b[0m             batch_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_trained_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dsaie\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for CNN:\n\tsize mismatch for decoder.upconvs.3.weight: copying a param with shape torch.Size([32, 1, 2, 2]) from checkpoint, the shape in current model is torch.Size([32, 96, 2, 2]).\n\tsize mismatch for decoder.upconvs.3.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.0.weight: copying a param with shape torch.Size([1, 32, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 32, 3, 3]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.0.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.weight: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.running_mean: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.1.running_var: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.3.weight: copying a param with shape torch.Size([1, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 96, 3, 3]).\n\tsize mismatch for decoder.dec_blocks.3.cnnblock.3.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([96])."
     ]
    }
   ],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias)]\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm2d(num_features=out_channels))\n",
    "        layers.append(nn.PReLU())\n",
    "        layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias))\n",
    "                \n",
    "        self.cnnblock = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnnblock(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=[32, 64, 128], kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_blocks = nn.ModuleList([\n",
    "            CNNBlock(channels[block], channels[block+1], kernel_size, padding, bias, \n",
    "                     batch_norm=batch_norm) \n",
    "            for block in range(len(channels)-1)]\n",
    "            )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for block in self.enc_blocks:\n",
    "            x = block(x)\n",
    "            outs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return outs\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels=[128, 64, 32], kernel_size=3, padding=1, bias=False, batch_norm=True):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.upconvs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(channels[block], channels[block+1], kernel_size=2, padding=0, stride=2) \n",
    "            for block in range(len(channels)-1)]\n",
    "            )\n",
    "        self.dec_blocks = nn.ModuleList([\n",
    "            CNNBlock(channels[block], channels[block+1], kernel_size, padding, bias, \n",
    "                     batch_norm=batch_norm)\n",
    "             for block in range(len(channels)-1)]\n",
    "             )\n",
    "        \n",
    "    def forward(self, x, x_skips):\n",
    "        for i in range(len(x_skips)):\n",
    "            x = self.upconvs[i](x)\n",
    "            x = torch.cat((x, x_skips[-(1+i)]), dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "\n",
    "        x = self.dec_blocks[-1](x)\n",
    "        return x\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, node_features, out_dim=96, n_downsamples=3, initial_hid_dim=64, batch_norm=True, \n",
    "                 bias=True):\n",
    "        super(CNN, self).__init__()\n",
    "        hidden_channels = [initial_hid_dim*2**i for i in range(n_downsamples)]\n",
    "        encoder_channels = [node_features]+hidden_channels\n",
    "        decoder_channels = list(reversed(hidden_channels))+[out_dim]\n",
    "\n",
    "        self.encoder = Encoder(encoder_channels, kernel_size=3, padding=1, \n",
    "                               bias=bias, batch_norm=batch_norm)\n",
    "        self.decoder = Decoder(decoder_channels, kernel_size=3, padding=1, \n",
    "                               bias=bias, batch_norm=batch_norm)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x[-1], x[:-1])\n",
    "        x = nn.Sigmoid()(x)\n",
    "        return x\n",
    "    \n",
    "node_features = 2\n",
    "model = CNN(node_features=node_features, n_downsamples=4, initial_hid_dim=32, \n",
    "            batch_norm=True, bias=True)\n",
    "model.load_state_dict(torch.load(pre_trained_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8211ff6",
   "metadata": {},
   "source": [
    "# Get losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(model, loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval() # specifies that the model is in evaluation mode\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch['Input']\n",
    "            y = batch['WD']  # [:,:,:,1]\n",
    "\n",
    "            # Model prediction\n",
    "            preds = model(x)\n",
    "\n",
    "            # MSE loss function\n",
    "            loss = nn.MSELoss()(preds, y)\n",
    "            losses.append(loss.cpu().detach())\n",
    "\n",
    "    losses = np.array(losses)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ac64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_loader = DataLoader(normalized_train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec7d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model validation\n",
    "test_loss = get_errors(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988e69d",
   "metadata": {},
   "source": [
    "# Visualize errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1d25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_loss, bins=20, edgecolor='black')\n",
    "\n",
    "plt.title('Histogram of Given Values')\n",
    "plt.xlabel('Errors')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0.000, 0.250)\n",
    "plt.ylim(0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2d340",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fad6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one sample\n",
    "data_id = 70\n",
    "x = normalized_train_dataset[data_id]['Input'].reshape(1, 2, 64, 64)\n",
    "\n",
    "pred_WD = model(x).detach()\n",
    "WD = normalized_train_dataset[data_id]['WD'][-1,:,:]\n",
    "pred_last_WD = pred_WD[:,-1,:,:]\n",
    "\n",
    "\n",
    "show_WD = WD.reshape(64,64)\n",
    "show_pred_WD = pred_last_WD.reshape(64,64)\n",
    "\n",
    "number_grids = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850f7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].imshow(show_WD.reshape(number_grids,number_grids), cmap='Blues_r', origin='lower')\n",
    "axs[0].set_title('WD target')\n",
    "\n",
    "axs[1].imshow(show_pred_WD.reshape(number_grids,number_grids), cmap='Blues_r', origin='lower')\n",
    "axs[1].set_title('WD prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff3112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
